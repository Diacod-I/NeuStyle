{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import vgg19\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-01-26T12:45:50.717174Z","iopub.execute_input":"2024-01-26T12:45:50.717828Z","iopub.status.idle":"2024-01-26T12:46:06.247075Z","shell.execute_reply.started":"2024-01-26T12:45:50.717788Z","shell.execute_reply":"2024-01-26T12:46:06.245728Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"base_image_path = keras.utils.get_file(\"paris.jpg\", \"https://i.imgur.com/F28w3Ac.jpg\")\nstyle_reference_image_path = keras.utils.get_file(\"starry_night.jpg\", \"https://i.imgur.com/9ooB60I.jpg\")\nresult_prefix = \"paris_generated\"\n\n# Weights of the different loss components\ntotal_variation_weight = 1e-6\nstyle_weight = 1e-6\ncontent_weight = 2.5e-8\n\n# Dimensions of the generated picture.\nwidth, height = keras.preprocessing.image.load_img(base_image_path).size\nimg_nrows = 400\nimg_ncols = int(width * img_nrows / height)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T12:46:06.249382Z","iopub.execute_input":"2024-01-26T12:46:06.250087Z","iopub.status.idle":"2024-01-26T12:46:06.516652Z","shell.execute_reply.started":"2024-01-26T12:46:06.250047Z","shell.execute_reply":"2024-01-26T12:46:06.515525Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading data from https://i.imgur.com/F28w3Ac.jpg\n102437/102437 [==============================] - 0s 0us/step\nDownloading data from https://i.imgur.com/9ooB60I.jpg\n935806/935806 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Utility Functions","metadata":{}},{"cell_type":"code","source":"def preprocess_image(image_path):\n    # Util function to open, resize and format pictures into appropriate tensors\n    img = keras.preprocessing.image.load_img(\n        image_path, target_size=(img_nrows, img_ncols)\n    )\n    img = keras.preprocessing.image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = vgg19.preprocess_input(img)\n    return tf.convert_to_tensor(img)\n\n\ndef deprocess_image(x):\n    # Util function to convert a tensor into a valid image\n    x = x.reshape((img_nrows, img_ncols, 3))\n    # Remove zero-center by mean pixel\n    x[:, :, 0] += 103.939\n    x[:, :, 1] += 116.779\n    x[:, :, 2] += 123.68\n    # 'BGR'->'RGB'\n    x = x[:, :, ::-1]\n    x = np.clip(x, 0, 255).astype(\"uint8\")\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-01-26T12:46:06.518522Z","iopub.execute_input":"2024-01-26T12:46:06.519033Z","iopub.status.idle":"2024-01-26T12:46:06.530414Z","shell.execute_reply.started":"2024-01-26T12:46:06.518986Z","shell.execute_reply":"2024-01-26T12:46:06.528686Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def gram_matrix(x):\n\t# The gram matrix of an image tensor (feature-wise outer product)\n    x = tf.transpose(x, (2, 0, 1))\n    features = tf.reshape(x, (tf.shape(x)[0], -1))\n    gram = tf.matmul(features, tf.transpose(features))\n    return gram\n    \ndef style_loss(style, combination):\n    S = gram_matrix(style)\n    C = gram_matrix(combination)\n    channels = 3\n    size = img_nrows * img_ncols\n    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n    \ndef content_loss(base, combination):\n    return tf.reduce_sum(tf.square(combination - base))\n    \ndef total_variation_loss(x):\n    a = tf.square(x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, 1:, : img_ncols - 1, :])\n    b = tf.square(x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, : img_nrows - 1, 1:, :])\n    return tf.reduce_sum(tf.pow(a + b, 1.25))","metadata":{"execution":{"iopub.status.busy":"2024-01-26T12:46:06.533323Z","iopub.execute_input":"2024-01-26T12:46:06.533865Z","iopub.status.idle":"2024-01-26T12:46:06.546252Z","shell.execute_reply.started":"2024-01-26T12:46:06.533826Z","shell.execute_reply":"2024-01-26T12:46:06.544968Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Build a VGG19 model loaded with pre-trained ImageNet weights\nmodel = vgg19.VGG19(weights=\"imagenet\", include_top=False)\n\n# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\noutputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n\n# Set up a model that returns the activation values for every layer in\n# VGG19 (as a dict).\nfeature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)\n\n# List of layers to use for the style loss.\nstyle_layer_names = [\n    \"block1_conv1\",\n    \"block2_conv1\",\n    \"block3_conv1\",\n    \"block4_conv1\",\n    \"block5_conv1\",\n]\n# The layer to use for the content loss.\ncontent_layer_name = \"block5_conv2\"\n\n\ndef compute_loss(combination_image, base_image, style_reference_image):\n    input_tensor = tf.concat(\n        [base_image, style_reference_image, combination_image], axis=0\n    )\n    features = feature_extractor(input_tensor)\n\n    # Initialize the loss\n    loss = tf.zeros(shape=())\n\n    # Add content loss\n    layer_features = features[content_layer_name]\n    base_image_features = layer_features[0, :, :, :]\n    combination_features = layer_features[2, :, :, :]\n    loss = loss + content_weight * content_loss(\n        base_image_features, combination_features\n    )\n    # Add style loss\n    for layer_name in style_layer_names:\n        layer_features = features[layer_name]\n        style_reference_features = layer_features[1, :, :, :]\n        combination_features = layer_features[2, :, :, :]\n        sl = style_loss(style_reference_features, combination_features)\n        loss += (style_weight / len(style_layer_names)) * sl\n\n    # Add total variation loss\n    loss += total_variation_weight * total_variation_loss(combination_image)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-01-26T12:46:06.548157Z","iopub.execute_input":"2024-01-26T12:46:06.548635Z","iopub.status.idle":"2024-01-26T12:46:10.300715Z","shell.execute_reply.started":"2024-01-26T12:46:06.548583Z","shell.execute_reply":"2024-01-26T12:46:10.299611Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"@tf.function\ndef compute_loss_and_grads(combination_image, base_image, style_reference_image):\n    with tf.GradientTape() as tape:\n        loss = compute_loss(combination_image, base_image, style_reference_image)\n    grads = tape.gradient(loss, combination_image)\n    return loss, grads\n    \noptimizer = keras.optimizers.SGD(\n    keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96\n    )\n)\n\nbase_image = preprocess_image(base_image_path)\nstyle_reference_image = preprocess_image(style_reference_image_path)\ncombination_image = tf.Variable(preprocess_image(base_image_path))\n\niterations = 200\nfor i in range(1, iterations + 1):\n    loss, grads = compute_loss_and_grads(\n        combination_image, base_image, style_reference_image\n    )\n    optimizer.apply_gradients([(grads, combination_image)])\n    print(\"Iteration %d: loss=%.2f\" % (i, loss))\n    img = deprocess_image(combination_image.numpy())\n    fname = result_prefix + \"_at_iteration_%d.png\" % i\n    keras.preprocessing.image.save_img(fname, img)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T13:20:31.472791Z","iopub.execute_input":"2024-01-26T13:20:31.473233Z","iopub.status.idle":"2024-01-26T14:03:10.193035Z","shell.execute_reply.started":"2024-01-26T13:20:31.473199Z","shell.execute_reply":"2024-01-26T14:03:10.191711Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Iteration 1: loss=130466.16\nIteration 2: loss=88985.02\nIteration 3: loss=62069.37\nIteration 4: loss=47923.60\nIteration 5: loss=40343.57\nIteration 6: loss=35955.93\nIteration 7: loss=33188.89\nIteration 8: loss=31201.61\nIteration 9: loss=29658.75\nIteration 10: loss=28410.04\nIteration 11: loss=27339.44\nIteration 12: loss=26421.81\nIteration 13: loss=25606.20\nIteration 14: loss=24884.16\nIteration 15: loss=24228.83\nIteration 16: loss=23635.16\nIteration 17: loss=23089.54\nIteration 18: loss=22587.44\nIteration 19: loss=22120.31\nIteration 20: loss=21685.09\nIteration 21: loss=21276.83\nIteration 22: loss=20893.70\nIteration 23: loss=20532.29\nIteration 24: loss=20190.54\nIteration 25: loss=19866.13\nIteration 26: loss=19557.75\nIteration 27: loss=19263.80\nIteration 28: loss=18983.46\nIteration 29: loss=18715.38\nIteration 30: loss=18458.79\nIteration 31: loss=18212.71\nIteration 32: loss=17976.35\nIteration 33: loss=17749.11\nIteration 34: loss=17530.60\nIteration 35: loss=17320.23\nIteration 36: loss=17117.42\nIteration 37: loss=16921.78\nIteration 38: loss=16732.91\nIteration 39: loss=16550.31\nIteration 40: loss=16373.59\nIteration 41: loss=16202.50\nIteration 42: loss=16036.81\nIteration 43: loss=15876.23\nIteration 44: loss=15720.39\nIteration 45: loss=15569.09\nIteration 46: loss=15422.17\nIteration 47: loss=15279.44\nIteration 48: loss=15140.75\nIteration 49: loss=15005.90\nIteration 50: loss=14874.73\nIteration 51: loss=14747.08\nIteration 52: loss=14622.82\nIteration 53: loss=14501.82\nIteration 54: loss=14383.95\nIteration 55: loss=14269.08\nIteration 56: loss=14157.09\nIteration 57: loss=14047.87\nIteration 58: loss=13941.28\nIteration 59: loss=13837.24\nIteration 60: loss=13735.69\nIteration 61: loss=13636.57\nIteration 62: loss=13539.78\nIteration 63: loss=13445.24\nIteration 64: loss=13352.90\nIteration 65: loss=13262.65\nIteration 66: loss=13174.40\nIteration 67: loss=13088.09\nIteration 68: loss=13003.68\nIteration 69: loss=12921.11\nIteration 70: loss=12840.29\nIteration 71: loss=12761.15\nIteration 72: loss=12683.66\nIteration 73: loss=12607.81\nIteration 74: loss=12533.49\nIteration 75: loss=12460.68\nIteration 76: loss=12389.30\nIteration 77: loss=12319.37\nIteration 78: loss=12250.84\nIteration 79: loss=12183.63\nIteration 80: loss=12117.71\nIteration 81: loss=12053.06\nIteration 82: loss=11989.63\nIteration 83: loss=11927.38\nIteration 84: loss=11866.29\nIteration 85: loss=11806.33\nIteration 86: loss=11747.47\nIteration 87: loss=11689.67\nIteration 88: loss=11632.93\nIteration 89: loss=11577.19\nIteration 90: loss=11522.46\nIteration 91: loss=11468.69\nIteration 92: loss=11415.85\nIteration 93: loss=11363.92\nIteration 94: loss=11312.87\nIteration 95: loss=11262.70\nIteration 96: loss=11213.38\nIteration 97: loss=11164.91\nIteration 98: loss=11117.25\nIteration 99: loss=11070.38\nIteration 100: loss=11024.29\nIteration 101: loss=10978.93\nIteration 102: loss=10934.29\nIteration 103: loss=10890.36\nIteration 104: loss=10847.13\nIteration 105: loss=10804.59\nIteration 106: loss=10762.71\nIteration 107: loss=10721.49\nIteration 108: loss=10680.90\nIteration 109: loss=10640.91\nIteration 110: loss=10601.51\nIteration 111: loss=10562.70\nIteration 112: loss=10524.48\nIteration 113: loss=10486.81\nIteration 114: loss=10449.69\nIteration 115: loss=10413.12\nIteration 116: loss=10377.08\nIteration 117: loss=10341.55\nIteration 118: loss=10306.54\nIteration 119: loss=10272.02\nIteration 120: loss=10237.99\nIteration 121: loss=10204.45\nIteration 122: loss=10171.38\nIteration 123: loss=10138.78\nIteration 124: loss=10106.63\nIteration 125: loss=10074.92\nIteration 126: loss=10043.63\nIteration 127: loss=10012.78\nIteration 128: loss=9982.36\nIteration 129: loss=9952.34\nIteration 130: loss=9922.72\nIteration 131: loss=9893.49\nIteration 132: loss=9864.65\nIteration 133: loss=9836.20\nIteration 134: loss=9808.11\nIteration 135: loss=9780.37\nIteration 136: loss=9753.00\nIteration 137: loss=9725.96\nIteration 138: loss=9699.28\nIteration 139: loss=9672.94\nIteration 140: loss=9646.92\nIteration 141: loss=9621.23\nIteration 142: loss=9595.85\nIteration 143: loss=9570.78\nIteration 144: loss=9546.00\nIteration 145: loss=9521.53\nIteration 146: loss=9497.35\nIteration 147: loss=9473.47\nIteration 148: loss=9449.87\nIteration 149: loss=9426.55\nIteration 150: loss=9403.51\nIteration 151: loss=9380.73\nIteration 152: loss=9358.22\nIteration 153: loss=9335.97\nIteration 154: loss=9313.98\nIteration 155: loss=9292.25\nIteration 156: loss=9270.76\nIteration 157: loss=9249.51\nIteration 158: loss=9228.50\nIteration 159: loss=9207.73\nIteration 160: loss=9187.19\nIteration 161: loss=9166.89\nIteration 162: loss=9146.81\nIteration 163: loss=9126.96\nIteration 164: loss=9107.33\nIteration 165: loss=9087.91\nIteration 166: loss=9068.71\nIteration 167: loss=9049.71\nIteration 168: loss=9030.90\nIteration 169: loss=9012.29\nIteration 170: loss=8993.88\nIteration 171: loss=8975.65\nIteration 172: loss=8957.62\nIteration 173: loss=8939.77\nIteration 174: loss=8922.10\nIteration 175: loss=8904.61\nIteration 176: loss=8887.30\nIteration 177: loss=8870.16\nIteration 178: loss=8853.20\nIteration 179: loss=8836.40\nIteration 180: loss=8819.77\nIteration 181: loss=8803.30\nIteration 182: loss=8787.00\nIteration 183: loss=8770.86\nIteration 184: loss=8754.87\nIteration 185: loss=8739.04\nIteration 186: loss=8723.37\nIteration 187: loss=8707.84\nIteration 188: loss=8692.46\nIteration 189: loss=8677.22\nIteration 190: loss=8662.13\nIteration 191: loss=8647.19\nIteration 192: loss=8632.38\nIteration 193: loss=8617.71\nIteration 194: loss=8603.19\nIteration 195: loss=8588.80\nIteration 196: loss=8574.55\nIteration 197: loss=8560.43\nIteration 198: loss=8546.43\nIteration 199: loss=8532.56\nIteration 200: loss=8518.82\n","output_type":"stream"}]}]}